{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hairy-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import operator\n",
    "import visualisation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dtw import dtw\n",
    "\n",
    "from sporco import plot, util\n",
    "from sporco.admm import cbpdn\n",
    "from sporco.dictlrn import cbpdndl\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "from itertools import tee\n",
    "\n",
    "import scipy.signal as sg\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-origin",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "necessary-tutorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Claudia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_TESTING_DATA = \"additional_files_dreem/X_train_denoised_array.h5\"\n",
    "PATH_TO_TRAINING_TARGET = \"data/y_train_tX9Br0C.csv\"\n",
    "h5_file = h5py.File(PATH_TO_TESTING_DATA)\n",
    "mask = np.array(pd.read_csv(PATH_TO_TRAINING_TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instrumental-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(h5_file.get('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indie-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4400, 9000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-benchmark",
   "metadata": {},
   "source": [
    "Separation of signals containing at least one apnea event and those who do do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "turned-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_apnea_signals = []\n",
    "idx_normal_signals = []\n",
    "for i in range(4400):\n",
    "    if 1 in mask[i,1:]:\n",
    "        idx_apnea_signals += [i]\n",
    "    else:\n",
    "        idx_normal_signals += [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-entity",
   "metadata": {},
   "source": [
    "## Exploration of respiratory signals for a normal sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-royalty",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_signals = 5\n",
    "chosen_signals = np.random.randint(len(idx_normal_signals),size=n_signals)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_signals, figsize=(20,10))\n",
    "for i in range(n_signals):\n",
    "    ax[i].plot(X_train[0,idx_normal_signals[chosen_signals[i]]])\n",
    "    ax[i].set_title(f\"Signal number {chosen_signals[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-disco",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_signals, figsize=(20,10))\n",
    "for i in range(n_signals):\n",
    "    ax[i].plot(X_train[1,idx_normal_signals[chosen_signals[i]]])\n",
    "    ax[i].set_title(f\"Signal number {chosen_signals[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_signals, figsize=(20,10))\n",
    "for i in range(n_signals):\n",
    "    ax[i].plot(X_train[2,idx_normal_signals[chosen_signals[i]]])\n",
    "    ax[i].set_title(f\"Signal number {chosen_signals[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-performer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_signals, figsize=(20,10))\n",
    "for i in range(n_signals):\n",
    "    ax[i].plot(X_train[3,idx_normal_signals[chosen_signals[i]]])\n",
    "    ax[i].set_title(f\"Signal number {chosen_signals[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-jaguar",
   "metadata": {},
   "source": [
    "## Utility functions for CDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CDL(signal, Z, D, figsize=(15, 10)):\n",
    "    \"\"\"Plot the learned dictionary `D` and the associated sparse codes `Z`.\n",
    "\n",
    "    `signal` is an univariate signal of shape (n_samples,) or (n_samples, 1).\n",
    "    \"\"\"\n",
    "    (atom_length, n_atoms) = np.shape(D)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(n_atoms + 1, 3, (2, 3))\n",
    "    plt.plot(signal)\n",
    "    for i in range(n_atoms):\n",
    "        plt.subplot(n_atoms + 1, 3, 3 * i + 4)\n",
    "        plt.plot(D[:, i])\n",
    "        plt.subplot(n_atoms + 1, 3, (3 * i + 5, 3 * i + 6))\n",
    "        plt.plot(Z[:, i])\n",
    "        plt.ylim((np.min(Z), np.max(Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atleast_2d(ary):\n",
    "    \"\"\"Reshape array to at least two dimensions.\"\"\"\n",
    "    if ary.ndim == 0:\n",
    "        return ary.reshape(1, 1)\n",
    "    elif ary.ndim == 1:\n",
    "        return ary[:, np.newaxis]\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_distance_matrix_as_table(\n",
    "    distance_matrix, labels=None, figsize=(8, 2)\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis(\"tight\")\n",
    "    ax.axis(\"off\")\n",
    "    norm = mpl.colors.Normalize()\n",
    "    cell_colours_hex = np.empty(shape=distance_matrix.shape, dtype=object)\n",
    "    cell_colours_rgba = plt.get_cmap(\"magma\")(norm(distance_matrix))\n",
    "\n",
    "    for i in range(distance_matrix.shape[0]):\n",
    "        for j in range(i + 1, distance_matrix.shape[0]):\n",
    "            cell_colours_hex[i, j] = rgb2hex(\n",
    "                cell_colours_rgba[i, j], keep_alpha=True\n",
    "            )\n",
    "            cell_colours_hex[j, i] = cell_colours_hex[i, j]\n",
    "\n",
    "    if labels is not None:\n",
    "        _ = ax.table(\n",
    "            cellText=distance_matrix,\n",
    "            colLabels=labels,\n",
    "            rowLabels=labels,\n",
    "            loc=\"center\",\n",
    "            cellColours=cell_colours_hex,\n",
    "        )\n",
    "    else:\n",
    "        _ = ax.table(\n",
    "            cellText=distance_matrix,\n",
    "            loc=\"center\",\n",
    "            cellColours=cell_colours_hex,\n",
    "        )\n",
    "\n",
    "    return ax\n",
    "\n",
    "def fig_ax(figsize=(15, 5)):\n",
    "    return plt.subplots(figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-recording",
   "metadata": {},
   "source": [
    "## CDL on a single signal\n",
    "\n",
    "For a 1D signal $\\mathbf{x}\\in\\mathbb{R}^N$ with $N$ samples, the convolutional dictionary learning tasks amounts to solving the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\min_{(\\mathbf{d}_k)_k, (\\mathbf{z}_k)_k \\\\ \\lVert\\mathbf{d}_k\\rVert^2\\leq 1} \\quad\\left\\lVert \\mathbf{x} - \\sum_{k=1}^K \\mathbf{z}_k * \\mathbf{d}_k \\right\\rVert^2 \\quad + \\quad\\lambda \\sum_{k=1}^K \\lVert\\mathbf{z}_k\\rVert_1\n",
    "$$\n",
    "\n",
    "where $\\mathbf{d}_k\\in\\mathbb{R}^L$ are the $K$ dictionary atoms (patterns), $\\mathbf{z}_k\\in\\mathbb{R}^{N-L+1}$ are activations signals, and $\\lambda>0$ is the sparsity constraint.\n",
    "\n",
    "This problem is not convex with respect to the couple $(\\mathbf{d}_k)_k, (\\mathbf{z}_k)_k$ but convex when the subproblems are taken individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, we set parameters and options that should probably remained unchanged\n",
    "PENALTY = 3\n",
    "\n",
    "# options for the dictionary learning and sparse coding procedures\n",
    "def get_opt_dl(penalty=PENALTY):\n",
    "    \"\"\"Return the option class for the dictionary learning\"\"\"\n",
    "    return cbpdndl.ConvBPDNDictLearn.Options(\n",
    "        {\n",
    "            \"Verbose\": False,\n",
    "            \"MaxMainIter\": 50,\n",
    "            \"CBPDN\": {\"rho\": 50.0 * penalty + 0.5, \"NonNegCoef\": True},\n",
    "            \"CCMOD\": {\"rho\": 10.0},\n",
    "        },\n",
    "        dmethod=\"cns\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_opt_sc():\n",
    "    \"\"\"Return the option class for the sparse coding\"\"\"\n",
    "    return cbpdn.ConvBPDN.Options(\n",
    "        {\n",
    "            \"Verbose\": False,\n",
    "            \"MaxMainIter\": 50,\n",
    "            \"RelStopTol\": 5e-3,\n",
    "            \"AuxVarObj\": False,\n",
    "            \"NonNegCoef\": True,  # only positive sparse codes\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-junction",
   "metadata": {},
   "source": [
    "Let's apply dictionary learning on the first normal signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Abdominal belt\", \"Airflow\", \"PPG\", \"Thoracic belt\", \"Snoring indicator\", \"SPO2\", \"C4-A1\", \"O2-A1\"]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize=(20,8))\n",
    "for i in range(4):\n",
    "    ax[i].plot(X_train[i, idx_normal_signals[1]])\n",
    "    ax[i].set_ylabel(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to change\n",
    "n_atoms = 3\n",
    "atom_length = 500\n",
    "penalty = 4\n",
    "\n",
    "# Select a signal\n",
    "signal = X_train[1, idx_normal_signals[0]]\n",
    "signal = atleast_2d(signal)  # reshape\n",
    "\n",
    "# Random number generator\n",
    "rng = np.random.RandomState(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get options for the optimizations\n",
    "opt_dl = get_opt_dl(penalty=penalty)\n",
    "opt_sc = get_opt_sc()\n",
    "\n",
    "# Dictionary learning and sparse coding\n",
    "dict_learning = cbpdndl.ConvBPDNDictLearn(\n",
    "    D0=rng.randn(atom_length, 1, n_atoms),  # random init\n",
    "    S=signal,  # signal at hand\n",
    "    lmbda=penalty,  # sparsity penalty\n",
    "    opt=opt_dl,  # options for the optimizations\n",
    "    xmethod=\"admm\",  # optimization method (sparse coding)\n",
    "    dmethod=\"cns\",  # optimization method (dict learnin)\n",
    ")\n",
    "atom_dictionary = dict_learning.solve()\n",
    "\n",
    "# retrieve the sparse codes\n",
    "basis_pursuit = cbpdn.ConvBPDN(\n",
    "    D=atom_dictionary,  # learned dictionary\n",
    "    S=signal,  # signal at hand\n",
    "    lmbda=penalty,  # sparsity penalty\n",
    "    opt=opt_sc,  # options for the optimizations\n",
    ")\n",
    "sparse_codes = basis_pursuit.solve().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CDL(\n",
    "    signal, atleast_2d(sparse_codes), atleast_2d(atom_dictionary.squeeze())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-avenue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reconstruction with the dictionary and the sparse codes\n",
    "reconstruction = np.stack(\n",
    "    [\n",
    "        np.convolve(code, atom, mode=\"valid\")\n",
    "        for (code, atom) in zip(\n",
    "            atleast_2d(sparse_codes).T, atleast_2d(atom_dictionary.squeeze()).T\n",
    "        )\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "# Note that the reconstruction has less samples than the original signal.\n",
    "# This is because of border effects of the convolution.\n",
    "offset = atom_length - 1\n",
    "\n",
    "fig, ax = fig_ax()\n",
    "tt = np.arange(signal.shape[0])\n",
    "ax.plot(tt, signal, label=\"original\", alpha=0.5)\n",
    "ax.plot(tt[offset:], reconstruction.sum(axis=0), label=\"reconstructed\")\n",
    "ax.set_title(\n",
    "    f\"Reconstruction MSE: {np.mean((signal[offset :].flatten() - reconstruction.sum(axis=0))**2):.2e}\"\n",
    ")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-vienna",
   "metadata": {},
   "source": [
    "Finding a dictionary is hard.\n",
    "Let's use peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_peaks(peaks, treshold):\n",
    "    time_diff_peaks = (peaks[1:] - peaks[:-1])/100.\n",
    "    #plt.hist(time_diff_peaks,10)\n",
    "    drop_values = np.where(time_diff_peaks < treshold)[0]\n",
    "    time_diff_peaks = np.delete(time_diff_peaks, drop_values)\n",
    "    return(np.delete(peaks,drop_values+1), time_diff_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-singer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal_id = idx_normal_signals[3383]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize = (20,8))\n",
    "for i in range(4):\n",
    "    signal_i = X_train[i, signal_id]\n",
    "    ax[i].plot(signal_i)\n",
    "    treshold = signal_i.mean()+ signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, time_peaks = keep_peaks(peaks, 0.6)\n",
    "    print(f\"Signal {i}\")\n",
    "    print(f\"Average interval between peaks : {time_peaks.mean():.2f}, var : {time_peaks.var():.2f}, median : {np.median(time_peaks):.2f}, min : {time_peaks.min():.2f}, max : {time_peaks.max():.2f}  \")\n",
    "    \n",
    "    ax[i].plot(peaks, signal_i[peaks], \"x\")\n",
    "    \n",
    "    ax[i].plot(np.zeros_like(signal_i)+ treshold, \"--\", color=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_id = idx_normal_signals[1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize = (20,8))\n",
    "for i in range(4):\n",
    "    signal_i = X_train[i, signal_id]\n",
    "    treshold = signal_i.mean()+ signal_i.std()\n",
    "    ax[i].plot(signal_i)\n",
    "    peaks, _ = sg.find_peaks(signal_i,height= treshold)\n",
    "    peaks, time_peaks = keep_peaks(peaks, 0.6)\n",
    "    print(f\"Signal {i}\")\n",
    "    print(f\"Average interval between peaks : {time_peaks.mean():.2f}, var : {time_peaks.var():.2f}, median : {np.median(time_peaks):.2f}, min : {time_peaks.min():.2f}, max : {time_peaks.max():.2f}  \")\n",
    "    \n",
    "    ax[i].plot(peaks, signal_i[peaks], \"x\")\n",
    "    ax[i].plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-municipality",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal_id = idx_apnea_signals[37]\n",
    "apneas_i = np.where(mask[signal_id] == 1)[0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize = (20,8))\n",
    "for i in range(4):\n",
    "    for idx in range(apneas_i.size):\n",
    "        ax[i].axvline(apneas_i[idx]*100, color='#ffb6c1', linewidth=10)\n",
    "    signal_i = X_train[i, signal_id]\n",
    "    ax[i].plot(signal_i)\n",
    "    treshold = signal_i.mean()+ signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, time_peaks = keep_peaks(peaks, 0.6)\n",
    "    print(f\"Signal {i}\")\n",
    "    print(f\"Average interval between peaks : {time_peaks.mean():.2f}, var : {time_peaks.var():.2f}, median : {np.median(time_peaks):.2f}, min : {time_peaks.min():.2f}, max : {time_peaks.max():.2f}  \")\n",
    "    \n",
    "    time_diff_peaks = []\n",
    "    #peaks, _ = sg.find_peaks(signal_i,height=0)\n",
    "    ax[i].plot(peaks, signal_i[peaks], \"x\")\n",
    "    ax[i].plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-semiconductor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal_id = idx_apnea_signals[100]\n",
    "apneas_i = np.where(mask[signal_id] == 1)[0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize = (20,8))\n",
    "for i in range(4):\n",
    "    for idx in range(apneas_i.size):\n",
    "        ax[i].axvline(apneas_i[idx]*100, color='#ffb6c1', linewidth=10)\n",
    "    signal_i = X_train[i, signal_id]\n",
    "    ax[i].plot(signal_i)\n",
    "    treshold = signal_i.mean()+ signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, mean = keep_peaks(peaks, 0.6)\n",
    "    print(mean)\n",
    "    \n",
    "    time_diff_peaks = []\n",
    "    #peaks, _ = sg.find_peaks(signal_i,height=0)\n",
    "    ax[i].plot(peaks, signal_i[peaks], \"x\")\n",
    "    ax[i].plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_id = idx_apnea_signals[500]\n",
    "apneas_i = np.where(mask[signal_id] == 1)[0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize = (20,8))\n",
    "for i in range(4):\n",
    "    for idx in range(apneas_i.size):\n",
    "        ax[i].axvline(apneas_i[idx]*100, color='#ffb6c1', linewidth=10)\n",
    "    signal_i = X_train[i, signal_id]\n",
    "    ax[i].plot(signal_i)\n",
    "    treshold = signal_i.mean()+ signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, time_peaks = keep_peaks(peaks, 0.6)\n",
    "    print(f\"Signal {i}\")\n",
    "    print(f\"Average interval between peaks : {time_peaks.mean():.2f}, var : {time_peaks.var():.2f}, median : {np.median(time_peaks):.2f}, min : {time_peaks.min():.2f}, max : {time_peaks.max():.2f}  \")\n",
    "    \n",
    "    time_diff_peaks = []\n",
    "    #peaks, _ = sg.find_peaks(signal_i,height=0)\n",
    "    ax[i].plot(peaks, signal_i[peaks], \"x\")\n",
    "    ax[i].plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_features_extractor(signal_id, dim, n_window=500, peak_param=1, time_treshold=0.5, plot=False):\n",
    "    \n",
    "    '''\n",
    "    Returns matrix of shape 9000 which computes the distance to the closest peak, as well as the\n",
    "    average value of the signal on a window of size n_window\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    signal_i = X_train[dim, signal_id]\n",
    "    treshold = signal_i.mean()+ peak_param*signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, mean = keep_peaks(peaks, time_treshold)\n",
    "    peaks_added = np.zeros(2 + peaks.size)\n",
    "    peaks_added[1:-1] = peaks\n",
    "    peaks_added[-1] = signal_i.size-1\n",
    "    \n",
    "    dist_matrix = np.zeros((signal_i.size,3))\n",
    "    mean_window = np.ones(n_window) / n_window\n",
    "    \n",
    "    next_peak_idx = 1\n",
    "    prev_peak_idx = 0\n",
    "    \n",
    "    \n",
    "    for i in range(signal_i.size):\n",
    "        dist_matrix[i,0] = (i - peaks_added[prev_peak_idx])/100\n",
    "        dist_matrix[i,1] = (peaks_added[next_peak_idx] - i)/100\n",
    "        \n",
    "        if i == peaks_added[next_peak_idx]:\n",
    "            next_peak_idx +=1\n",
    "            prev_peak_idx +=1\n",
    "            \n",
    "    \n",
    "    dist_matrix[:, 2] = np.convolve(signal_i, n_window, 'same' )\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(20,5))\n",
    "        apneas_i = np.where(mask[signal_id] == 1)[0]\n",
    "        for idx in range(apneas_i.size):\n",
    "            ax.axvline(apneas_i[idx]*100, color='#ffb6c1', linewidth=10)\n",
    "        \n",
    "        ax.plot(signal_i)\n",
    "        ax.plot(peaks, signal_i[peaks], \"x\")\n",
    "        ax.plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")\n",
    "        ax.set_ylabel(labels[dim])\n",
    "        \n",
    "    \n",
    "    return(dist_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-drive",
   "metadata": {},
   "source": [
    "bandpass filters on eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fossil-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_id = idx_apnea_signals[500]\n",
    "apneas_i = np.where(mask[signal_id] == 1)[0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, figsize = (20,8))\n",
    "for i in range(4):\n",
    "    for idx in range(apneas_i.size):\n",
    "        ax[i].axvline(apneas_i[idx]*100, color='#ffb6c1', linewidth=10)\n",
    "    signal_i = X_train[i, signal_id]\n",
    "    ax[i].plot(signal_i)\n",
    "    treshold = signal_i.mean()+ signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, time_peaks = keep_peaks(peaks, 0.6)\n",
    "    print(f\"Signal {i}\")\n",
    "    print(f\"Average interval between peaks : {time_peaks.mean():.2f}, var : {time_peaks.var():.2f}, median : {np.median(time_peaks):.2f}, min : {time_peaks.min():.2f}, max : {time_peaks.max():.2f}  \")\n",
    "    \n",
    "    time_diff_peaks = []\n",
    "    #peaks, _ = sg.find_peaks(signal_i,height=0)\n",
    "    ax[i].plot(peaks, signal_i[peaks], \"x\")\n",
    "    ax[i].plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_alpha = butter_bandpass_filter(signal_apnea, 8, 12, fs, order=3)\n",
    "y_beta = butter_bandpass_filter(signal_apnea, 16, 40, fs, order=3)\n",
    "y_sigma = butter_bandpass_filter(signal_apnea, 12, 16, fs, order=3)\n",
    "y_delta = butter_bandpass_filter(signal_apnea, 0.25, 4, fs, order=3)\n",
    "y_theta = butter_bandpass_filter(signal_apnea, 4, 8, fs, order=3)\n",
    "\n",
    "y_bands = np.asarray([y_delta, y_theta, y_alpha, y_sigma, y_beta])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "#ax.plot(y_delta, label=\"delta: 0.25-4Hz\")\n",
    "ax.plot(y_theta, label=\"theta: 4-8Hz\")\n",
    "ax.plot(y_alpha, label=\"alpha: 8-12Hz \")\n",
    "ax.plot(y_sigma, label=\"sigma: 12-16Hz\")\n",
    "ax.plot(y_beta, label=\"beta: 16-40Hz\")\n",
    "ax.plot(signal_apnea, c='k', label='signal')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-promotion",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(y_alpha)\n",
    "#plt.plot(y_beta)\n",
    "#plt.plot(y_delta)\n",
    "\n",
    "fig, (ax,ax1) = plt.subplots(nrows = 2, figsize=(20,10))\n",
    "ax.plot(y_delta[:300], label=\"delta: 0.25-4Hz\")\n",
    "ax.plot(y_theta[:300], label=\"theta: 4-8Hz\")\n",
    "ax.plot(y_alpha[:300], label=\"alpha: 8-12Hz \")\n",
    "ax.plot(y_sigma[:300], label=\"sigma: 12-16Hz\")\n",
    "ax.plot(y_beta[:300], label=\"beta: 16-40Hz\")\n",
    "ax.plot(signal_apnea[:300], c='k', label='signal')\n",
    "ax.legend()\n",
    "ax.set_title(\"Zoom sur le signal pendant le sommeil normal\")\n",
    "\n",
    "#ax1.plot(np.cumsum(y_delta[:100]**2), label=\"delta: 0.25-4Hz\")\n",
    "ax1.plot(y_delta[2500:2800], label=\"delta: 0.25-4Hz\")\n",
    "ax1.plot(y_theta[2500:2800], label=\"theta: 4-8Hz\")\n",
    "ax1.plot(y_alpha[2500:2800], label=\"alpha: 8-12Hz \")\n",
    "ax1.plot(y_sigma[2500:2800], label=\"sigma: 12-16Hz\")\n",
    "ax1.plot(y_beta[2500:2800], label=\"beta: 16-40Hz\")\n",
    "ax1.plot(signal_apnea[2500:2800], c='k', label='signal')\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Zoom sur le signal pendant une épisode d'apnée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "overall-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode, skew\n",
    "\n",
    "signals = [\"d\", \"t\", \"a\", \"s\", \"b\"]\n",
    "features = [\"energy\", \"entropy\", \"variance\", \"std\", \"mean\", \"median\", \"mode\", \"min\", \"max\"]\n",
    "\n",
    "def energy(signal):\n",
    "    return(np.sum(signal**2))\n",
    "\n",
    "def entropy(signal):\n",
    "    return(np.sum(signal**2*np.log(signal**2)))\n",
    "\n",
    "def features_subsignal(signal):\n",
    "    \n",
    "    ener = energy(signal)\n",
    "    entro = entropy(signal)\n",
    "    var = signal.var()\n",
    "    std = signal.std()\n",
    "    mean = signal.mean()\n",
    "    median = np.median(signal)\n",
    "    mod = mode(signal)[0][0]\n",
    "    mini = signal.min()\n",
    "    maxi = signal.max()\n",
    "    \n",
    "    return(np.asarray([ener,entro,var,std,mean,median,mod,mini,maxi]))\n",
    "\n",
    "def features_signal(signal, half_window_size=150, window_overlap=15):\n",
    "    \n",
    "    l_features = []\n",
    "    \n",
    "    i=0\n",
    "    cnt =0\n",
    "    while i < half_window_size:\n",
    "        l_features += [features_subsignal(signal[:i + half_window_size])]\n",
    "        i += window_overlap\n",
    "        cnt +=1\n",
    "\n",
    "    while i + half_window_size < signal.size :\n",
    "        l_features += [features_subsignal(signal[i-half_window_size: i + half_window_size ])]\n",
    "        i += window_overlap\n",
    "        cnt +=1\n",
    "    while i < signal.size:\n",
    "        l_features += [features_subsignal(signal[i-half_window_size: ])]\n",
    "        i += window_overlap\n",
    "        cnt +=1\n",
    "    return(np.asarray(l_features))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "following-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_features_extraction(signal_id, half_window_size=150, window_overlap= 15, n_window=100, peak_param=1, time_treshold=0.5):\n",
    "    \n",
    "    n_samples, idx = compute_idx(half_window_size, window_overlap,9000)\n",
    "    \n",
    "    feature_matrix = np.zeros((n_samples, 3*4))\n",
    "    \n",
    "    for i in range(4):\n",
    "        feature_matrix[:, 3*i:3*(i+1)] = peak_features_extractor(signal_id, dim=i, n_window=n_window,\n",
    "                                                peak_param=peak_param, time_treshold=time_treshold)[idx]\n",
    "        \n",
    "    return(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_bands = np.zeros((4400,9000,12))\n",
    "\n",
    "\n",
    "for i in range(4400):\n",
    "    eeg_bands[i] = signal_features_extractor(i)\n",
    "    if i%100 == 0:\n",
    "        print(f\"Extracted features of {i+1} signals\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adapted-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_features_extractor(signal_id, dim, n_window=100, peak_param=1, time_treshold=0.5, plot=False):\n",
    "    \n",
    "    '''\n",
    "    Returns matrix of shape 9000 which computes the distance to the closest peak, as well as the\n",
    "    average value of the signal on a window of size n_window\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    signal_i = X_train[dim, signal_id]\n",
    "    treshold = signal_i.mean()+ peak_param*signal_i.std()\n",
    "    peaks, _ = sg.find_peaks(signal_i,height=treshold)\n",
    "    peaks, mean = keep_peaks(peaks, time_treshold)\n",
    "    peaks_added = np.zeros(2 + peaks.size)\n",
    "    peaks_added[1:-1] = peaks\n",
    "    peaks_added[-1] = signal_i.size-1\n",
    "    \n",
    "    dist_matrix = np.zeros((signal_i.size,3))\n",
    "    mean_window = np.ones(n_window) / n_window\n",
    "    \n",
    "    next_peak_idx = 1\n",
    "    prev_peak_idx = 0\n",
    "    \n",
    "    \n",
    "    for i in range(signal_i.size):\n",
    "        dist_matrix[i,0] = (i - peaks_added[prev_peak_idx])/100\n",
    "        dist_matrix[i,1] = (peaks_added[next_peak_idx] - i)/100\n",
    "        \n",
    "        if i == peaks_added[next_peak_idx]:\n",
    "            next_peak_idx +=1\n",
    "            prev_peak_idx +=1\n",
    "            \n",
    "    \n",
    "    dist_matrix[:, 2] = np.convolve(signal_i, n_window, 'same' )\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(20,5))\n",
    "        apneas_i = np.where(mask[signal_id] == 1)[0]\n",
    "        for idx in range(apneas_i.size):\n",
    "            ax.axvline(apneas_i[idx]*100, color='#ffb6c1', linewidth=10)\n",
    "        \n",
    "        ax.plot(signal_i)\n",
    "        ax.plot(peaks, signal_i[peaks], \"x\")\n",
    "        ax.plot(np.zeros_like(signal_i)+treshold, \"--\", color=\"gray\")\n",
    "        ax.set_ylabel(labels[dim])\n",
    "        \n",
    "    \n",
    "    return(dist_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banned-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idx(half_window, overlap, length):\n",
    "    cnt = 0\n",
    "    idx = []\n",
    "    i=0\n",
    "    while i + half_window < length:\n",
    "        cnt+=1\n",
    "        idx +=[i]\n",
    "        i += overlap\n",
    "    while i < length:\n",
    "        cnt+=1\n",
    "        idx +=[i]\n",
    "        i += overlap\n",
    "        \n",
    "    return(cnt, idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-aaron",
   "metadata": {},
   "source": [
    "## BAND EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_features_extractor(signal_idx, fs=100):\n",
    "    \"\"\"\n",
    "    Order is\n",
    "    - First EEG sinal\n",
    "    - delta\n",
    "    - theta\n",
    "    - alpha\n",
    "    - sigma\n",
    "    - beta\n",
    "    \n",
    "    - Second EEG signal\n",
    "    (same order for the bands)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    feature_matrix = np.zeros((9000, 6*2))\n",
    "    feature_matrix[:,0] = X_train[6, signal_idx]\n",
    "    feature_matrix[:,1] = butter_bandpass_filter(X_train[6, signal_idx], 0.25, 4, fs, order=3)\n",
    "    feature_matrix[:,2] = butter_bandpass_filter(X_train[6, signal_idx], 4, 8, fs, order=3)\n",
    "    feature_matrix[:,3] = butter_bandpass_filter(X_train[6, signal_idx], 8, 12, fs, order=3)\n",
    "    feature_matrix[:,4] = butter_bandpass_filter(X_train[6, signal_idx], 16, 40, fs, order=3)\n",
    "    feature_matrix[:,5] = butter_bandpass_filter(X_train[6, signal_idx], 12, 16, fs, order=3)\n",
    "    \n",
    "\n",
    "    feature_matrix[:,6] = X_train[7, signal_idx]\n",
    "    feature_matrix[:,7] = butter_bandpass_filter(X_train[7, signal_idx], 0.25, 4, fs, order=3)\n",
    "    feature_matrix[:,8] = butter_bandpass_filter(X_train[7, signal_idx], 4, 8, fs, order=3)\n",
    "    feature_matrix[:,9] = butter_bandpass_filter(X_train[7, signal_idx], 8, 12, fs, order=3)\n",
    "    feature_matrix[:,10] = butter_bandpass_filter(X_train[7, signal_idx], 16, 40, fs, order=3)\n",
    "    feature_matrix[:,11] = butter_bandpass_filter(X_train[7, signal_idx], 12, 16, fs, order=3)\n",
    "        \n",
    "        #feature_matrix[:, col_idx:col_idx+9] = features_signal(y_alpha, half_window_size, window_overlap)\n",
    "        #col_idx +=9\n",
    "        #feature_matrix[:, col_idx:col_idx+9] = features_signal(y_beta, half_window_size, window_overlap)\n",
    "        #col_idx +=9\n",
    "        #feature_matrix[:, col_idx:col_idx+9] = features_signal(y_sigma, half_window_size, window_overlap)\n",
    "        #col_idx +=9\n",
    "        #feature_matrix[:, col_idx:col_idx+9] = features_signal(y_delta, half_window_size, window_overlap)\n",
    "        #col_idx +=9\n",
    "        #feature_matrix[:, col_idx:col_idx+9] = features_signal(y_theta, half_window_size, window_overlap)\n",
    "        #col_idx +=9\n",
    "    return(feature_matrix)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "russian-exhaust",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features of 1 signals\n",
      "Extracted features of 101 signals\n",
      "Extracted features of 201 signals\n",
      "Extracted features of 301 signals\n",
      "Extracted features of 401 signals\n",
      "Extracted features of 501 signals\n",
      "Extracted features of 601 signals\n",
      "Extracted features of 701 signals\n",
      "Extracted features of 801 signals\n",
      "Extracted features of 901 signals\n",
      "Extracted features of 1001 signals\n",
      "Extracted features of 1101 signals\n",
      "Extracted features of 1201 signals\n",
      "Extracted features of 1301 signals\n",
      "Extracted features of 1401 signals\n",
      "Extracted features of 1501 signals\n",
      "Extracted features of 1601 signals\n",
      "Extracted features of 1701 signals\n",
      "Extracted features of 1801 signals\n",
      "Extracted features of 1901 signals\n",
      "Extracted features of 2001 signals\n",
      "Extracted features of 2101 signals\n",
      "Extracted features of 2201 signals\n",
      "Extracted features of 2301 signals\n",
      "Extracted features of 2401 signals\n",
      "Extracted features of 2501 signals\n",
      "Extracted features of 2601 signals\n",
      "Extracted features of 2701 signals\n",
      "Extracted features of 2801 signals\n",
      "Extracted features of 2901 signals\n",
      "Extracted features of 3001 signals\n",
      "Extracted features of 3101 signals\n",
      "Extracted features of 3201 signals\n",
      "Extracted features of 3301 signals\n",
      "Extracted features of 3401 signals\n",
      "Extracted features of 3501 signals\n",
      "Extracted features of 3601 signals\n",
      "Extracted features of 3701 signals\n",
      "Extracted features of 3801 signals\n",
      "Extracted features of 3901 signals\n",
      "Extracted features of 4001 signals\n",
      "Extracted features of 4101 signals\n",
      "Extracted features of 4201 signals\n",
      "Extracted features of 4301 signals\n"
     ]
    }
   ],
   "source": [
    "eeg_bands = np.zeros((4400,9000,12))\n",
    "\n",
    "\n",
    "for i in range(4400):\n",
    "    eeg_bands[i] = signal_features_extractor(i)\n",
    "    if i%100 == 0:\n",
    "        print(f\"Extracted features of {i+1} signals\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "scientific-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('features/bands_train_patients.h5', 'w')\n",
    "h5f.create_dataset('data', data=eeg_bands)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-collar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
